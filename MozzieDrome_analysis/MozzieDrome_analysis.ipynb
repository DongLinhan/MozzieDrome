{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885337be-33df-46b3-a0a3-b305c4ca4289",
   "metadata": {},
   "source": [
    "# MozzieDrome analysis\n",
    "### Linhan Dong, Duvall Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b03566-ac15-43c8-9d38-5150ff2b3230",
   "metadata": {},
   "source": [
    "### Generate files needed for further analysis and behavior classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d55f7-855d-4835-802f-50a2426ed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "def getfile(file_path):\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        locations = fill_missing(locations)\n",
    "        BODY_INDEX = 0\n",
    "        body_loc = locations[:, BODY_INDEX, :, :]\n",
    "        return body_loc\n",
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    initial_shape = Y.shape\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "        Y[:, i] = y\n",
    "    Y = Y.reshape(initial_shape)\n",
    "    return Y\n",
    "\n",
    "def individual_velocity(file_path, delay):\n",
    "    body_loc = getfile(file_path)\n",
    "    delay_frame = int(delay * 60)\n",
    "    for i in range(0, body_loc.shape[2]):\n",
    "        filter_input = body_loc[:,:,i]\n",
    "        distance_list = []\n",
    "        for k in range(1, len(filter_input)):\n",
    "            x1, y1 = filter_input[k - 1]  # Previous coordinates\n",
    "            x2, y2 = filter_input[k]      # Current coordinates\n",
    "            distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            distance_list.append(distance)\n",
    "        column_name = str(file_path) + str(i)\n",
    "        print(column_name)\n",
    "        distances = pd.Series(distance_list) \n",
    "        zero_series = pd.Series([0] * delay_frame)\n",
    "        corrected_distances = pd.concat([zero_series, distances], ignore_index=True)\n",
    "        all_individual_distances[column_name] = corrected_distances\n",
    "        window_size = 300\n",
    "        corrected_distances_array = corrected_distances.to_numpy()\n",
    "        sum_windows = len(corrected_distances_array) // window_size\n",
    "        distances_collapsed = np.array([np.sum(corrected_distances_array[i * window_size:(i + 1) * window_size]) for i in range(sum_windows)])\n",
    "        distances_collapsed = distances_collapsed[1:360]\n",
    "        all_collapsed_individual_distances[column_name] = distances_collapsed\n",
    "\n",
    "def vector_length(file_path, delay):\n",
    "    body_loc = getfile(file_path)\n",
    "    delay_frame = int(delay * 60)\n",
    "    for i in range(0, body_loc.shape[2]):\n",
    "        filter_input = body_loc[:,:,i]\n",
    "        distance_list = []\n",
    "        window_size = 300\n",
    "        start_frame = 300 - delay_frame\n",
    "        vector_windows = (len(filter_input) + delay_frame - 241) // window_size\n",
    "        for k in range(0, vector_windows):\n",
    "            x1, y1 = filter_input[start_frame + k * window_size]  # Previous coordinates\n",
    "            x2, y2 = filter_input[start_frame + (k+1) * window_size]      # Current coordinates\n",
    "            distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            distance_list.append(distance)\n",
    "        column_name = str(file_path) + str(i)\n",
    "        print(column_name)\n",
    "        distances = pd.Series(distance_list) \n",
    "        all_vector_lengths[column_name] = distances\n",
    "\n",
    "def max_velocity(file_path, delay):\n",
    "    body_loc = getfile(file_path)\n",
    "    delay_frame = int(delay * 60)\n",
    "    for i in range(0, body_loc.shape[2]):\n",
    "        filter_input = body_loc[:,:,i]\n",
    "        distance_list = []\n",
    "        for k in range(1, len(filter_input)):\n",
    "            x1, y1 = filter_input[k - 1]  # Previous coordinates\n",
    "            x2, y2 = filter_input[k]      # Current coordinates\n",
    "            distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            distance_list.append(distance)\n",
    "        column_name = str(file_path) + str(i)\n",
    "        print(column_name)\n",
    "        distances = pd.Series(distance_list) \n",
    "        zero_series = pd.Series([0] * delay_frame)\n",
    "        corrected_distances = pd.concat([zero_series, distances], ignore_index=True)\n",
    "        all_individual_distances[column_name] = corrected_distances\n",
    "        window_size = 300\n",
    "        corrected_distances_array = corrected_distances.to_numpy()\n",
    "        max_windows = len(corrected_distances_array) // window_size\n",
    "        max_velocity_array = np.array([np.max(corrected_distances_array[i * window_size:(i + 1) * window_size]) for i in range(max_windows)])\n",
    "        max_velocity = max_velocity_array[1:360]\n",
    "        all_max_velocity[column_name] = max_velocity\n",
    "\n",
    "folder_path = '/Users/donglinhan/Desktop/SLEAP/FinalH5/WT-DD2'\n",
    "h5_files = os.listdir(folder_path)\n",
    "h5_files = natsorted(h5_files)\n",
    "all_individual_distances = pd.DataFrame()\n",
    "all_collapsed_individual_distances = pd.DataFrame()\n",
    "all_vector_lengths = pd.DataFrame(index = range(370))\n",
    "all_max_velocity = pd.DataFrame()\n",
    "\n",
    "for file_name in h5_files:\n",
    "    if file_name.endswith('.h5'):\n",
    "        file_parts = file_name.split('_')\n",
    "        first_six_chars = file_parts[1][:6]\n",
    "        delay = float(first_six_chars.lstrip(\"0\"))\n",
    "        print(delay)\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(file_name)\n",
    "        individual_velocity(file_path, delay)\n",
    "        vector_length(file_path, delay)\n",
    "        max_velocity(file_path, delay)\n",
    "\n",
    "all_collapsed_individual_distances.to_excel('WT_DD2_collapsed_distances_300.xlsx', index=False)\n",
    "all_vector_lengths.to_excel('WT_DD2_vector_lengths_300.xlsx', index=False)\n",
    "all_max_velocity.to_excel('WT_DD2_max_velocity_300.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4bddb-5acc-4037-80e2-32f437bd5453",
   "metadata": {},
   "source": [
    "### Generate behavior classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03804aa7-b92d-47d5-8fbd-9625ee0c56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "\n",
    "vector_input = '/Users/donglinhan/Desktop/SLEAP/WT_DD2_vector_lengths_300.xlsx'\n",
    "distance_input = '/Users/donglinhan/Desktop/SLEAP/WT_DD2_collapsed_distances_300.xlsx'\n",
    "max_velocity_input = '/Users/donglinhan/Desktop/SLEAP/WT_DD2_max_velocity_300.xlsx'\n",
    "distances = pd.read_excel(distance_input)\n",
    "vector_lengths = pd.read_excel(vector_input)\n",
    "max_velocities = pd.read_excel(max_velocity_input)\n",
    "total = len(distances.columns)\n",
    "all_behavior = pd.DataFrame()\n",
    "for i, column_name in enumerate(distances.columns):\n",
    "    behavior_list = []\n",
    "    for k in range (0, 143):\n",
    "        if distances[column_name][k] >= 175:\n",
    "            behavior_list.append(2)\n",
    "        elif vector_lengths[column_name][k] > 5 and distances[column_name][k] < 175:\n",
    "            if max_velocities[column_name][k] > 4:\n",
    "                behavior_list.append(2)\n",
    "            else:\n",
    "                behavior_list.append(1)\n",
    "        else:\n",
    "            behavior_list.append(0)\n",
    "    behavior = np.array(behavior_list) \n",
    "    print(i)\n",
    "    all_behavior[column_name] = behavior\n",
    "all_behavior.to_excel('WT_DD2_all_behavior_modified_again.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c720e-c1b5-4b5f-829d-9c535c694d3d",
   "metadata": {},
   "source": [
    "### All LD activity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57df647a-b3fd-4eb5-bbab-f0558c0f8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LD acute vs sustained activity analysis\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "\n",
    "wt_behavior_input = '/Users/donglinhan/Desktop/SLEAP/WT_LDfull_all_behavior_modified_again.xlsx'\n",
    "het_behavior_input = '/Users/donglinhan/Desktop/SLEAP/Het_LD_all_behavior_modified_again.xlsx'\n",
    "hom_behavior_input = '/Users/donglinhan/Desktop/SLEAP/PDF_LDfull_all_behavior_modified_again.xlsx'\n",
    "wt_behaviors_original = pd.read_excel(wt_behavior_input)\n",
    "het_behaviors_original = pd.read_excel(het_behavior_input)\n",
    "hom_behaviors_original = pd.read_excel(hom_behavior_input)\n",
    "wt_behaviors = wt_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "het_behaviors = het_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "hom_behaviors = hom_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "wt_activity_input = '/Users/donglinhan/Desktop/SLEAP/WT_LDfull_all_collapsed_distances_300.xlsx'\n",
    "het_activity_input = '/Users/donglinhan/Desktop/SLEAP/HET_LD_all_collapsed_distances_300.xlsx'\n",
    "hom_activity_input = '/Users/donglinhan/Desktop/SLEAP/PDF_LDfull_all_collapsed_distances_300.xlsx'\n",
    "wt_activities = pd.read_excel(wt_activity_input)\n",
    "het_activities = pd.read_excel(het_activity_input)\n",
    "hom_activities = pd.read_excel(hom_activity_input)\n",
    "\n",
    "\n",
    "def calculate_total_activity(activity_series):\n",
    "    # Step 1: Identify the initiation of activity\n",
    "    start_index = next((i for i, x in enumerate(activity_series) if x != 0), None)\n",
    "    if start_index is None:\n",
    "        return 0  # No activity in the series\n",
    "    \n",
    "    # Step 2: Identify the end of activity\n",
    "    end_index = None\n",
    "    for i in range(len(activity_series) - 48):\n",
    "        if activity_series[i] != 0 and all(x == 0 for x in activity_series[i+1:i+49]):\n",
    "            end_index = i\n",
    "            break\n",
    "    \n",
    "    if end_index is None:\n",
    "        end_index = next((i for i in range(len(activity_series) - 1, -1, -1) if activity_series[i] != 0), start_index)\n",
    "    \n",
    "    # Step 3: Sum the activity\n",
    "    total_activity = sum(activity_series[start_index:end_index + 1])\n",
    "    \n",
    "    return total_activity\n",
    "\n",
    "def calculate_total_activity(activity_series):\n",
    "    # Step 1: Identify the initiation of activity\n",
    "    start_index = next((i for i, x in enumerate(activity_series) if x != 0), None)\n",
    "    if start_index is None:\n",
    "        return 0  # No activity in the series\n",
    "    \n",
    "    # Step 2: Identify the end of activity\n",
    "    end_index = None\n",
    "    for i in range(len(activity_series) - 48):\n",
    "        if activity_series[i] != 0 and all(x == 0 for x in activity_series[i+1:i+49]):\n",
    "            end_index = i\n",
    "            break\n",
    "    \n",
    "    if end_index is None:\n",
    "        end_index = next((i for i in range(len(activity_series) - 1, -1, -1) if activity_series[i] != 0), start_index)\n",
    "    \n",
    "    # Step 3: Sum the activity\n",
    "    total_activity = sum(activity_series[start_index:end_index + 1])\n",
    "    \n",
    "    return total_activity\n",
    "\n",
    "def average_activity_bout_length(activity_series):\n",
    "    bout_lengths = []\n",
    "    current_bout = 0\n",
    "    \n",
    "    for activity in activity_series:\n",
    "        if activity == 1:\n",
    "            current_bout += 1\n",
    "        else:\n",
    "            if current_bout > 0:\n",
    "                bout_lengths.append(current_bout)\n",
    "            current_bout = 0\n",
    "    \n",
    "    # Check the last bout\n",
    "    if current_bout > 0:\n",
    "        bout_lengths.append(current_bout)\n",
    "    \n",
    "    if bout_lengths:\n",
    "        average_length = sum(bout_lengths) / len(bout_lengths)\n",
    "    else:\n",
    "        average_length = 0\n",
    "        \n",
    "    return average_length\n",
    "\n",
    "def median_active_time(activity, time_points):\n",
    "    # Identify active times where activity is 1 (walking) or 2 (flying)\n",
    "    active_times = time_points[(activity == 1) | (activity == 2)]\n",
    "    if len(active_times) > 0:\n",
    "        return np.median(active_times) / 60  # Convert seconds to minutes\n",
    "    else:\n",
    "        return np.nan  # No active times\n",
    "\n",
    "WT_ZT_timepoints = {\n",
    "    '0': range(0, 70),   \n",
    "    '3': range(70, 150),  \n",
    "    '6': range(150, 220), \n",
    "    '9': range(220, 300),\n",
    "    '12': range(300, 380),\n",
    "    '15': range(380, 460),\n",
    "    '18': range(460, 530),\n",
    "    '21': range(530, 600),\n",
    "}\n",
    "\n",
    "HET_ZT_timepoints = {\n",
    "    '0': range(0, 60),   \n",
    "    '3': range(60, 120),  \n",
    "    '6': range(120, 180), \n",
    "    '9': range(180, 240),\n",
    "    '12': range(240, 300),\n",
    "    '15': range(300, 360),\n",
    "    '18': range(360, 420),\n",
    "    '21': range(420, 480),\n",
    "}\n",
    "\n",
    "HOM_ZT_timepoints = {\n",
    "    '0': range(0, 58),   \n",
    "    '3': range(58, 116),  \n",
    "    '6': range(116, 174), \n",
    "    '9': range(174, 232),\n",
    "    '12': range(232, 290),\n",
    "    '15': range(290, 347),\n",
    "    '18': range(347, 404),\n",
    "    '21': range(404, 462),\n",
    "}\n",
    "\n",
    "\n",
    "wt_total_sustained_activity_6_10 = pd.DataFrame(index = range(100)) \n",
    "wt_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "wt_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "wt_total_walk = pd.DataFrame(index = range(100)) \n",
    "wt_total_flight = pd.DataFrame(index = range(100)) \n",
    "wt_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "het_total_sustained_activity_6_10 = pd.DataFrame(index = range(100)) \n",
    "het_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "het_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "het_total_walk = pd.DataFrame(index = range(100)) \n",
    "het_total_flight = pd.DataFrame(index = range(100)) \n",
    "het_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "hom_total_sustained_activity_6_10 = pd.DataFrame(index = range(100)) \n",
    "hom_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "hom_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "hom_total_walk = pd.DataFrame(index = range(100)) \n",
    "hom_total_flight = pd.DataFrame(index = range(100)) \n",
    "hom_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "time_points = np.arange(0, 600, 5)\n",
    "\n",
    "for ZT, cols in WT_ZT_timepoints.items():\n",
    "    wt_behavior_data = wt_behaviors.iloc[:, cols]\n",
    "    wt_activity_data = wt_activities.iloc[:,cols]\n",
    "    wt_behavior_type = wt_behaviors_original.iloc[:, cols]\n",
    "    wt_walk = []\n",
    "    wt_flight = []\n",
    "    wt_sustained_activity_6_10 = []\n",
    "    wt_acute_activity = []\n",
    "    wt_average_bout = []\n",
    "    wt_median_time = []\n",
    "    for i in wt_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(wt_behavior_data[i]))\n",
    "        if wt_behavior_data[i][23:47].sum() > 0 and wt_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = wt_activity_data[i][95:143].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(wt_behavior_data[i]))\n",
    "            acute_activity = wt_activity_data[i][23:47].sum() \n",
    "            walk = wt_behavior_type[i][23:143].value_counts().get(1, 0)\n",
    "            flight = wt_behavior_type[i][23:143].value_counts().get(2, 0)\n",
    "            median_time = median_active_time(wt_behavior_type[i][23:143], time_points)\n",
    "        elif wt_behavior_data[i][23:47].sum() == 0 and wt_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            acute_activity = wt_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:\n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            acute_activity = None\n",
    "            median_time = None\n",
    "\n",
    "        wt_sustained_activity_6_10.append(sustained_activity_6_10)\n",
    "        wt_average_bout.append(average_bout)\n",
    "        wt_acute_activity.append(acute_activity)\n",
    "        wt_walk.append(walk)\n",
    "        wt_flight.append(flight)\n",
    "        wt_median_time.append(median_time)\n",
    "    wt_total_sustained_activity_6_10[ZT] = pd.Series(wt_sustained_activity_6_10)\n",
    "    wt_total_average_bout[ZT] = pd.Series(wt_average_bout)\n",
    "    wt_total_acute_activity[ZT] = pd.Series(wt_acute_activity)\n",
    "    wt_total_walk[ZT] = pd.Series(wt_walk)\n",
    "    wt_total_flight[ZT] = pd.Series(wt_flight)\n",
    "    wt_total_median_time[ZT] = pd.Series(wt_median_time)\n",
    "\n",
    "for ZT, cols in HET_ZT_timepoints.items():\n",
    "    het_behavior_data = het_behaviors.iloc[:, cols]\n",
    "    het_activity_data = het_activities.iloc[:,cols]\n",
    "    het_behavior_type = het_behaviors_original.iloc[:, cols]\n",
    "    \n",
    "    het_walk = []\n",
    "    het_flight = []\n",
    "    het_sustained_activity_6_10 = []\n",
    "    het_acute_activity = []\n",
    "    het_average_bout = []\n",
    "    het_median_time = []\n",
    "    \n",
    "    for i in het_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(het_behavior_data[i]))\n",
    "        if het_behavior_data[i][23:47].sum() > 0 and het_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = het_activity_data[i][95:143].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(het_behavior_data[i]))\n",
    "            acute_activity = het_activity_data[i][23:47].sum() \n",
    "            walk = het_behavior_type[i][23:sustained_index+1].value_counts().get(1, 0)\n",
    "            flight = het_behavior_type[i][23:sustained_index+1].value_counts().get(2, 0)\n",
    "            median_time = median_active_time(het_behavior_type[i][23:143], time_points)\n",
    "        elif het_behavior_data[i][23:47].sum() == 0 and het_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            acute_activity = het_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:\n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            acute_activity = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            median_time = None\n",
    "        het_sustained_activity_6_10.append(sustained_activity_6_10)\n",
    "        het_average_bout.append(average_bout)\n",
    "        het_acute_activity.append(acute_activity)\n",
    "        het_walk.append(walk)\n",
    "        het_flight.append(flight)\n",
    "        het_median_time.append(median_time)\n",
    "    het_total_sustained_activity_6_10[ZT] = pd.Series(het_sustained_activity_6_10)\n",
    "    het_total_average_bout[ZT] = pd.Series(het_average_bout)\n",
    "    het_total_acute_activity[ZT] = pd.Series(het_acute_activity)\n",
    "    het_total_walk[ZT] = pd.Series(het_walk)\n",
    "    het_total_flight[ZT] = pd.Series(het_flight)\n",
    "    het_total_median_time[ZT] = pd.Series(het_median_time)\n",
    "\n",
    "for ZT, cols in HOM_ZT_timepoints.items():\n",
    "    hom_behavior_data = hom_behaviors.iloc[:, cols]\n",
    "    hom_activity_data = hom_activities.iloc[:,cols]\n",
    "    hom_behavior_type = hom_behaviors_original.iloc[:, cols]\n",
    "    hom_walk = []\n",
    "    hom_flight = []\n",
    "    hom_sustained_activity_6_10 = []\n",
    "    hom_acute_activity = []\n",
    "    hom_average_bout = []\n",
    "    hom_median_time = []\n",
    "    for i in hom_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(hom_behavior_data[i]))\n",
    "        if hom_behavior_data[i][23:47].sum() > 0 and hom_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = hom_activity_data[i][95:143].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(hom_behavior_data[i]))\n",
    "            acute_activity = hom_activity_data[i][23:47].sum() \n",
    "            walk = hom_behavior_type[i][23:sustained_index+1].value_counts().get(1, 0)\n",
    "            flight = hom_behavior_type[i][23:sustained_index+1].value_counts().get(2, 0)\n",
    "            median_time = median_active_time(hom_behavior_type[i][23:143], time_points)\n",
    "        elif hom_behavior_data[i][23:47].sum() == 0 and hom_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            acute_activity = hom_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:  \n",
    "            sustained_activity_6_10 = None\n",
    "            average_bout = None\n",
    "            acute_activity = None\n",
    "            walk = None\n",
    "            flight = None\n",
    "            median_time = None\n",
    "        hom_sustained_activity_6_10.append(sustained_activity_6_10)\n",
    "        hom_average_bout.append(average_bout)\n",
    "        hom_acute_activity.append(acute_activity)\n",
    "        hom_walk.append(walk)\n",
    "        hom_flight.append(flight)\n",
    "        hom_median_time.append(median_time)\n",
    "    hom_total_sustained_activity_6_10[ZT] = pd.Series(hom_sustained_activity_6_10)\n",
    "    hom_total_average_bout[ZT] = pd.Series(hom_average_bout)\n",
    "    hom_total_acute_activity[ZT] = pd.Series(hom_acute_activity)\n",
    "    hom_total_walk[ZT] = pd.Series(hom_walk)\n",
    "    hom_total_flight[ZT] = pd.Series(hom_flight)\n",
    "    hom_total_median_time[ZT] = pd.Series(hom_median_time)\n",
    "\n",
    "\n",
    "wt_total_sustained_activity_6_10_output_file_path = 'persistence_analysis/wt_ld_total_sustained_activity_6_10.xlsx'\n",
    "wt_total_average_bout_output_file_path = 'persistence_analysis/wt_ld_total_average_bout.xlsx'\n",
    "wt_total_acute_activity_output_file_path = 'persistence_analysis/wt_ld_total_acute_activity.xlsx'\n",
    "wt_total_walk_output_file_path = 'persistence_analysis/wt_ld_total_walk.xlsx'\n",
    "wt_total_flight_output_file_path = 'persistence_analysis/wt_ld_total_flight.xlsx'\n",
    "wt_total_median_time_output_file_path = 'persistence_analysis/wt_ld_total_median_time.xlsx'\n",
    "\n",
    "het_total_sustained_activity_6_10_output_file_path = 'persistence_analysis/het_ld_total_sustained_activity_6_10.xlsx'\n",
    "het_total_average_bout_output_file_path = 'persistence_analysis/het_ld_total_average_bout.xlsx'\n",
    "het_total_acute_activity_output_file_path = 'persistence_analysis/het_ld_total_acute_activity.xlsx'\n",
    "het_total_walk_output_file_path = 'persistence_analysis/het_ld_total_walk.xlsx'\n",
    "het_total_flight_output_file_path = 'persistence_analysis/het_ld_total_flight.xlsx'\n",
    "het_total_median_time_output_file_path = 'persistence_analysis/het_ld_total_median_time.xlsx'\n",
    "\n",
    "hom_total_sustained_activity_6_10_output_file_path = 'persistence_analysis/hom_ld_total_sustained_activity_6_10.xlsx'\n",
    "hom_total_average_bout_output_file_path = 'persistence_analysis/hom_ld_total_average_bout.xlsx'\n",
    "hom_total_acute_activity_output_file_path = 'persistence_analysis/hom_ld_total_acute_activity.xlsx'\n",
    "hom_total_walk_output_file_path = 'persistence_analysis/hom_ld_total_walk.xlsx'\n",
    "hom_total_flight_output_file_path = 'persistence_analysis/hom_ld_total_flight.xlsx'\n",
    "hom_total_median_time_output_file_path = 'persistence_analysis/hom_ld_total_median_time.xlsx'\n",
    "\n",
    "wt_total_sustained_activity_6_10.to_excel(wt_total_sustained_activity_6_10_output_file_path, index=False)\n",
    "wt_total_average_bout.to_excel(wt_total_average_bout_output_file_path, index=False)\n",
    "wt_total_acute_activity.to_excel(wt_total_acute_activity_output_file_path, index=False)\n",
    "wt_total_walk.to_excel(wt_total_walk_output_file_path, index=False)\n",
    "wt_total_flight.to_excel(wt_total_flight_output_file_path, index=False)\n",
    "wt_total_median_time.to_excel(wt_total_median_time_output_file_path, index=False)\n",
    "\n",
    "het_total_sustained_activity_6_10.to_excel(het_total_sustained_activity_6_10_output_file_path, index=False)\n",
    "het_total_average_bout.to_excel(het_total_average_bout_output_file_path, index=False)\n",
    "het_total_acute_activity.to_excel(het_total_acute_activity_output_file_path, index=False)\n",
    "het_total_walk.to_excel(het_total_walk_output_file_path, index=False)\n",
    "het_total_flight.to_excel(het_total_flight_output_file_path, index=False)\n",
    "het_total_median_time.to_excel(het_total_median_time_output_file_path, index=False)\n",
    "\n",
    "hom_total_sustained_activity_6_10.to_excel(hom_total_sustained_activity_6_10_output_file_path, index=False)\n",
    "hom_total_average_bout.to_excel(hom_total_average_bout_output_file_path, index=False)\n",
    "hom_total_acute_activity.to_excel(hom_total_acute_activity_output_file_path, index=False)\n",
    "hom_total_walk.to_excel(hom_total_walk_output_file_path, index=False)\n",
    "hom_total_flight.to_excel(hom_total_flight_output_file_path, index=False)\n",
    "hom_total_median_time.to_excel(hom_total_median_time_output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615fbb0-eaf9-4d4c-8169-948f8c8d418c",
   "metadata": {},
   "source": [
    "### All DD activity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00317e55-cb90-4b63-be6f-f4d9adaa9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DD activity\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "\n",
    "wt_behavior_input = '/Users/donglinhan/Desktop/SLEAP/WT_DD2_all_behavior_modified_again.xlsx'\n",
    "het_behavior_input = '/Users/donglinhan/Desktop/SLEAP/Het_DD2_all_behavior_modified_again.xlsx'\n",
    "hom_behavior_input = '/Users/donglinhan/Desktop/SLEAP/PDF_DD2_all_behavior_modified_again.xlsx'\n",
    "wt_behaviors_original = pd.read_excel(wt_behavior_input)\n",
    "het_behaviors_original = pd.read_excel(het_behavior_input)\n",
    "hom_behaviors_original = pd.read_excel(hom_behavior_input)\n",
    "wt_behaviors = wt_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "het_behaviors = het_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "hom_behaviors = hom_behaviors_original.applymap(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "wt_activity_input = '/Users/donglinhan/Desktop/SLEAP/WT_DD2_collapsed_distances_300.xlsx'\n",
    "het_activity_input = '/Users/donglinhan/Desktop/SLEAP/HET_DD2_all_collapsed_distances_300.xlsx'\n",
    "hom_activity_input = '/Users/donglinhan/Desktop/SLEAP/PDF_DD2_all_collapsed_distances_300.xlsx'\n",
    "wt_activities = pd.read_excel(wt_activity_input)\n",
    "het_activities = pd.read_excel(het_activity_input)\n",
    "hom_activities = pd.read_excel(hom_activity_input)\n",
    "\n",
    "def calculate_end_index(activity_series):\n",
    "    start_index = next((i for i, x in enumerate(activity_series) if x != 0), None)\n",
    "    if start_index is None:\n",
    "        return 0  \n",
    "    end_index = None\n",
    "    for i in range(len(activity_series) - 48):\n",
    "        if activity_series[i] != 0 and all(x == 0 for x in activity_series[i+1:i+49]):\n",
    "            end_index = i\n",
    "            break\n",
    "    if end_index is None:\n",
    "        end_index = next((i for i in range(len(activity_series) - 1, -1, -1) if activity_series[i] != 0), start_index)\n",
    "    return end_index\n",
    "\n",
    "def average_activity_bout_length(activity_series):\n",
    "    bout_lengths = []\n",
    "    current_bout = 0\n",
    "    for activity in activity_series:\n",
    "        if activity == 1:\n",
    "            current_bout += 1\n",
    "        else:\n",
    "            if current_bout > 0:\n",
    "                bout_lengths.append(current_bout)\n",
    "            current_bout = 0\n",
    "    if current_bout > 0:\n",
    "        bout_lengths.append(current_bout)\n",
    "    if bout_lengths:\n",
    "        average_length = sum(bout_lengths) / len(bout_lengths)\n",
    "    else:\n",
    "        average_length = 0\n",
    "    return average_length\n",
    "\n",
    "def median_active_time(activity, time_points):\n",
    "    # Identify active times where activity is 1 (walking) or 2 (flying)\n",
    "    active_times = time_points[(activity == 1) | (activity == 2)]\n",
    "    if len(active_times) > 0:\n",
    "        return np.median(active_times) / 60  # Convert seconds to minutes\n",
    "    else:\n",
    "        return np.nan  # No active times\n",
    "\n",
    "WT_CT_timepoints = {\n",
    "    '0': range(0, 30),   \n",
    "    '3': range(30, 60),  \n",
    "    '6': range(60, 90), \n",
    "    '9': range(90, 120),\n",
    "    '12': range(120, 150),\n",
    "    '15': range(150, 180),\n",
    "    '18': range(180, 210),\n",
    "    '21': range(210, 240),\n",
    "}\n",
    "\n",
    "HET_CT_timepoints = {\n",
    "    '0': range(0, 20),   \n",
    "    '3': range(20, 40),  \n",
    "    '6': range(40, 60), \n",
    "    '9': range(60, 80),\n",
    "    '12': range(80, 100),\n",
    "    '15': range(100, 120),\n",
    "    '18': range(120, 140),\n",
    "    '21': range(140, 160),\n",
    "}\n",
    "\n",
    "HOM_CT_timepoints = {\n",
    "    '0': range(0, 29),   \n",
    "    '3': range(29, 58),  \n",
    "    '6': range(58, 87), \n",
    "    '9': range(87, 116),\n",
    "    '12': range(116, 145),\n",
    "    '15': range(145, 174),\n",
    "    '18': range(174, 203),\n",
    "    '21': range(203, 232),\n",
    "}\n",
    "\n",
    "wt_total_sustained_activity = pd.DataFrame(index = range(100)) \n",
    "wt_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "wt_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "wt_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "het_total_sustained_activity = pd.DataFrame(index = range(100)) \n",
    "het_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "het_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "het_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "hom_total_sustained_activity = pd.DataFrame(index = range(100)) \n",
    "hom_total_acute_activity = pd.DataFrame(index = range(100)) \n",
    "hom_total_average_bout = pd.DataFrame(index = range(100)) \n",
    "hom_total_median_time = pd.DataFrame(index = range(100)) \n",
    "\n",
    "time_points = np.arange(0, 600, 5)\n",
    "\n",
    "for CT, cols in WT_CT_timepoints.items():\n",
    "    wt_behavior_data = wt_behaviors.iloc[:, cols]\n",
    "    wt_activity_data = wt_activities.iloc[:,cols]\n",
    "    wt_behavior_type = wt_behaviors_original.iloc[:, cols]\n",
    "    wt_sustained_activity = []\n",
    "    wt_sustained_time = []\n",
    "    wt_longest_bout = []\n",
    "    wt_acute_activity = []\n",
    "    wt_average_bout = []\n",
    "    wt_median_time = []\n",
    "    for i in wt_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(wt_behavior_data[i]))\n",
    "        if wt_behavior_data[i][23:47].sum() > 0 and wt_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = wt_activity_data[i][47:sustained_index+1].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(wt_behavior_data[i]))\n",
    "            acute_activity = wt_activity_data[i][23:47].sum() \n",
    "            median_time = median_active_time(wt_behavior_type[i][23:143], time_points)\n",
    "        elif wt_behavior_data[i][23:47].sum() == 0 and wt_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = wt_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:\n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = None\n",
    "            median_time = None\n",
    "        wt_sustained_activity.append(sustained_activity)\n",
    "        wt_average_bout.append(average_bout)\n",
    "        wt_acute_activity.append(acute_activity)\n",
    "        wt_median_time.append(median_time)\n",
    "    wt_total_sustained_activity[CT] = pd.Series(wt_sustained_activity)\n",
    "    wt_total_average_bout[CT] = pd.Series(wt_average_bout)\n",
    "    wt_total_acute_activity[CT] = pd.Series(wt_acute_activity)\n",
    "    wt_total_median_time[CT] = pd.Series(wt_median_time)\n",
    "\n",
    "for CT, cols in HET_CT_timepoints.items():\n",
    "    het_behavior_data = het_behaviors.iloc[:, cols]\n",
    "    het_activity_data = het_activities.iloc[:,cols]\n",
    "    het_behavior_type = het_behaviors_original.iloc[:, cols]\n",
    "    het_sustained_activity = []\n",
    "    het_acute_activity = []\n",
    "    het_average_bout = []\n",
    "    het_median_time = []\n",
    "    for i in het_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(het_behavior_data[i]))\n",
    "        if het_behavior_data[i][23:47].sum() > 0 and het_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = het_activity_data[i][47:sustained_index+1].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(het_behavior_data[i]))\n",
    "            acute_activity = het_activity_data[i][23:47].sum() \n",
    "            median_time = median_active_time(het_behavior_type[i][23:143], time_points)\n",
    "        elif het_behavior_data[i][23:47].sum() == 0 and het_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = het_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:\n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = None\n",
    "            median_time = None\n",
    "        het_sustained_activity.append(sustained_activity)\n",
    "        het_average_bout.append(average_bout)\n",
    "        het_acute_activity.append(acute_activity)\n",
    "        het_median_time.append(median_time)\n",
    "    het_total_sustained_activity[CT] = pd.Series(het_sustained_activity)\n",
    "    het_total_average_bout[CT] = pd.Series(het_average_bout)\n",
    "    het_total_acute_activity[CT] = pd.Series(het_acute_activity)\n",
    "    het_total_median_time[CT] = pd.Series(het_median_time)\n",
    "\n",
    "for CT, cols in HOM_CT_timepoints.items():\n",
    "    hom_behavior_data = hom_behaviors.iloc[:, cols]\n",
    "    hom_activity_data = hom_activities.iloc[:,cols]\n",
    "    hom_behavior_type = hom_behaviors_original.iloc[:, cols]\n",
    "    hom_sustained_activity = []\n",
    "    hom_acute_activity = []\n",
    "    hom_average_bout = []\n",
    "    hom_median_time = []\n",
    "    for i in hom_behavior_data:\n",
    "        sustained_index = calculate_end_index(pd.Series(hom_behavior_data[i]))\n",
    "        if hom_behavior_data[i][23:47].sum() > 0 and hom_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = hom_activity_data[i][47:sustained_index+1].sum() \n",
    "            average_bout = average_activity_bout_length(pd.Series(hom_behavior_data[i]))\n",
    "            acute_activity = hom_activity_data[i][23:47].sum() \n",
    "            median_time = median_active_time(hom_behavior_type[i][23:143], time_points)\n",
    "        elif hom_behavior_data[i][23:47].sum() == 0 and hom_behavior_data[i][0:23].sum() == 0: \n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = hom_activity_data[i][23:47].sum() \n",
    "            median_time = None\n",
    "        else:\n",
    "            sustained_activity = None\n",
    "            average_bout = None\n",
    "            acute_activity = None\n",
    "            median_time = None\n",
    "        hom_sustained_activity.append(sustained_activity)\n",
    "        hom_average_bout.append(average_bout)\n",
    "        hom_acute_activity.append(acute_activity)\n",
    "        hom_median_time.append(median_time)\n",
    "    hom_total_sustained_activity[CT] = pd.Series(hom_sustained_activity)\n",
    "    hom_total_average_bout[CT] = pd.Series(hom_average_bout)\n",
    "    hom_total_acute_activity[CT] = pd.Series(hom_acute_activity)\n",
    "    hom_total_median_time[CT] = pd.Series(hom_median_time)\n",
    "\n",
    "wt_total_sustained_activity_output_file_path = 'persistence_analysis/wt_dd_total_sustained_activity.xlsx'\n",
    "wt_total_average_bout_output_file_path = 'persistence_analysis/wt_dd_total_average_bout.xlsx'\n",
    "wt_total_acute_activity_output_file_path = 'persistence_analysis/wt_dd_total_acute_activity.xlsx'\n",
    "wt_total_median_time_output_file_path = 'persistence_analysis/wt_dd_total_median_time.xlsx'\n",
    "\n",
    "het_total_sustained_activity_output_file_path = 'persistence_analysis/het_dd_total_sustained_activity.xlsx'\n",
    "het_total_average_bout_output_file_path = 'persistence_analysis/het_dd_total_average_bout.xlsx'\n",
    "het_total_acute_activity_output_file_path = 'persistence_analysis/het_dd_total_acute_activity.xlsx'\n",
    "het_total_median_time_output_file_path = 'persistence_analysis/het_dd_total_median_time.xlsx'\n",
    "\n",
    "hom_total_sustained_activity_output_file_path = 'persistence_analysis/hom_dd_total_sustained_activity.xlsx'\n",
    "hom_total_average_bout_output_file_path = 'persistence_analysis/hom_dd_total_average_bout.xlsx'\n",
    "hom_total_acute_activity_output_file_path = 'persistence_analysis/hom_dd_total_acute_activity.xlsx'\n",
    "hom_total_median_time_output_file_path = 'persistence_analysis/hom_dd_total_median_time.xlsx'\n",
    "\n",
    "wt_total_sustained_activity.to_excel(wt_total_sustained_activity_output_file_path, index=False)\n",
    "wt_total_average_bout.to_excel(wt_total_average_bout_output_file_path, index=False)\n",
    "wt_total_acute_activity.to_excel(wt_total_acute_activity_output_file_path, index=False)\n",
    "wt_total_median_time.to_excel(wt_total_median_time_output_file_path, index=False)\n",
    "\n",
    "het_total_sustained_activity.to_excel(het_total_sustained_activity_output_file_path, index=False)\n",
    "het_total_average_bout.to_excel(het_total_average_bout_output_file_path, index=False)\n",
    "het_total_acute_activity.to_excel(het_total_acute_activity_output_file_path, index=False)\n",
    "het_total_median_time.to_excel(het_total_median_time_output_file_path, index=False)\n",
    "\n",
    "hom_total_sustained_activity.to_excel(hom_total_sustained_activity_output_file_path, index=False)\n",
    "hom_total_average_bout.to_excel(hom_total_average_bout_output_file_path, index=False)\n",
    "hom_total_acute_activity.to_excel(hom_total_acute_activity_output_file_path, index=False)\n",
    "hom_total_median_time.to_excel(hom_total_median_time_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937f7f3-eb54-4817-97d4-dc1bba9d63c5",
   "metadata": {},
   "source": [
    "### Calculate reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadfb82-52f5-490b-8fa9-531d15ed727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "def getfile(file_path):\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        locations = fill_missing(locations)\n",
    "        BODY_INDEX = 0\n",
    "        body_loc = locations[:, BODY_INDEX, :, :]\n",
    "        return body_loc\n",
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    initial_shape = Y.shape\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "        Y[:, i] = y\n",
    "    Y = Y.reshape(initial_shape)\n",
    "    return Y\n",
    "\n",
    "\n",
    "def individual_velocity(file_path, delay):\n",
    "    body_loc = getfile(file_path)\n",
    "    delay_frame = int(delay * 60)\n",
    "    for i in range(0, body_loc.shape[2]):\n",
    "        filter_input = body_loc[:,:,i]\n",
    "        distance_list = []\n",
    "        for k in range(1, len(filter_input)):\n",
    "            x1, y1 = filter_input[k - 1]  # Previous coordinates\n",
    "            x2, y2 = filter_input[k]      # Current coordinates\n",
    "            distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            distance_list.append(distance)\n",
    "        column_name = str(file_path) + str(i)\n",
    "        print(column_name)\n",
    "        distances = pd.Series(distance_list) \n",
    "        zero_series = pd.Series([0] * delay_frame)\n",
    "        corrected_distances = pd.concat([zero_series, distances], ignore_index=True)\n",
    "        all_individual_distances[column_name] = corrected_distances\n",
    "        window_size = 300\n",
    "        corrected_distances_array = corrected_distances.to_numpy()\n",
    "        sum_windows = len(corrected_distances_array) // window_size\n",
    "        distances_collapsed = np.array([np.sum(corrected_distances_array[i * window_size:(i + 1) * window_size]) for i in range(sum_windows)])\n",
    "        all_collapsed_individual_distances[column_name] = distances_collapsed\n",
    "\n",
    "\n",
    "folder_path = '/Users/donglinhan/Desktop/SLEAP/FinalH5/WT-LD-full'\n",
    "h5_files = os.listdir(folder_path)\n",
    "h5_files = natsorted(h5_files)\n",
    "all_individual_distances = pd.DataFrame()\n",
    "all_collapsed_individual_distances = pd.DataFrame()\n",
    "\n",
    "for file_name in h5_files:\n",
    "    if file_name.endswith('.h5'):\n",
    "        file_parts = file_name.split('_')\n",
    "        first_six_chars = file_parts[1][:6]\n",
    "        delay = float(first_six_chars.lstrip(\"0\"))\n",
    "        print(delay)\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(file_name)\n",
    "        individual_velocity(file_path, delay)\n",
    "\n",
    "all_individual_distances.to_excel('WT-LDfull_individual_distances.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c49723-db42-4ec2-883f-23718e0c1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "input = '/Users/donglinhan/Desktop/SLEAP/WT-LDfull_individual_distances.xlsx'\n",
    "raw_individual_distances = pd.read_excel(input)\n",
    "window_size = 15\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "smoothed_individual_distances = pd.DataFrame()\n",
    "for c in raw_individual_distances.columns:\n",
    "    smoothed_individual_distances[c] = savgol_filter(raw_individual_distances[c], 30, 3)\n",
    "\n",
    "def no_repeats(numbers):\n",
    "    first_numbers = []\n",
    "    i = 0\n",
    "    while i < len(numbers):\n",
    "        start_num = numbers[i]  # Current number\n",
    "        end_num = start_num     # End of the sequence\n",
    "        while i + 1 < len(numbers) and numbers[i + 1] == end_num + 1:\n",
    "            end_num = numbers[i + 1]\n",
    "            i += 1\n",
    "        first_numbers.append(start_num)\n",
    "        i += 1  # Move to the next number\n",
    "    return first_numbers\n",
    "\n",
    "    \n",
    "all_activity_starts = pd.DataFrame(index = range(50)) \n",
    "for d in smoothed_individual_distances.columns:\n",
    "    print(d)\n",
    "    if smoothed_individual_distances[d].sum() > 500:\n",
    "        activity_starts = []\n",
    "        for i in range(len(smoothed_individual_distances[d]) - window_size*2):\n",
    "            window_pre_movement = smoothed_individual_distances[d][i:i+window_size].sum()\n",
    "            window_post_movement = smoothed_individual_distances[d][i+window_size:i+window_size+window_size].sum()\n",
    "            if window_post_movement > 3 * window_pre_movement and window_post_movement > 100:\n",
    "                activity_starts.append(i+window_size)\n",
    "    else:\n",
    "        activity_starts = []\n",
    "    activity_starts = no_repeats(activity_starts)\n",
    "    all_activity_starts[d] = pd.Series(activity_starts)\n",
    "    #all_activity_starts = all_activity_starts.append(pd.DataFrame([activity_starts], columns = str(d)), ignore_index=True)\n",
    "\n",
    "all_activity_starts.to_excel('WT-LDfull_all_activity_starts_15frames.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a981da3-0d7b-4db8-93b8-cf758d2345a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input = '/Users/donglinhan/Desktop/SLEAP/WT-LDfull_all_activity_starts_15frames.xlsx'\n",
    "all_activity_starts = pd.read_excel(input)\n",
    "\n",
    "all_reaction_time = pd.DataFrame()\n",
    "\n",
    "for i in all_activity_starts.columns:\n",
    "    start_times = all_activity_starts[i].dropna()\n",
    "    if start_times.isna().all():\n",
    "        reaction_time = None\n",
    "    else:\n",
    "        if 5400 < start_times.iloc[0] < 7200:\n",
    "            reaction_time = None\n",
    "        else:\n",
    "            print(start_times)\n",
    "            filtered_start_times = start_times[start_times >= 7200]\n",
    "            if filtered_start_times.empty:\n",
    "                reaction_time = None\n",
    "            else:\n",
    "                reaction_time = filtered_start_times.iloc[0]\n",
    "                reaction_time = (reaction_time - 7200) * 1/60\n",
    "                if reaction_time > 60:\n",
    "                    reaction_time = None\n",
    "    all_reaction_time = pd.concat([all_reaction_time, pd.DataFrame({'Exp': [i], 'Reaction Time': [reaction_time]})], ignore_index=True)\n",
    "\n",
    "print(all_reaction_time)\n",
    "\n",
    "output_file = 'WT-LDfull_all_reaction_times_15frames.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    all_reaction_time.to_excel(writer, index=False)\n",
    "\n",
    "print(f'Reaction times saved to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
